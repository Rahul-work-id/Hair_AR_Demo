<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>MediaPipe + Babylon.js AR Hat</title>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.babylonjs.com/babylon.js"></script>
  <script src="https://cdn.babylonjs.com/loaders/babylon.glTF2FileLoader.js"></script>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      overflow: hidden;
      background: black;
    }
    video {
      display: none;
    }
    canvas {
      width: 100vw;
      height: 100vh;
      display: block;
    }
  </style>
</head>
<body>
  <video id="video" autoplay playsinline></video>
  <canvas id="renderCanvas"></canvas>

  <script>
    const canvas = document.getElementById("renderCanvas");
    const engine = new BABYLON.Engine(canvas, true);
    const scene = new BABYLON.Scene(engine);
    const camera = new BABYLON.FreeCamera("cam", new BABYLON.Vector3(0, 0, -10), scene);
    camera.setTarget(BABYLON.Vector3.Zero());
    const light = new BABYLON.HemisphericLight("light", new BABYLON.Vector3(1, 1, 0), scene);

    // Load a GLB hat model or use a placeholder sphere
    let hat = BABYLON.MeshBuilder.CreateSphere("hat", {diameter: 1}, scene);
    hat.position.z = 1;

    // If you want to load a .glb hat instead, uncomment this:
    /*
    BABYLON.SceneLoader.ImportMesh("", "https://models.babylonjs.com/", "boombox.glb", scene, (meshes) => {
      hat = meshes[0];
      hat.scaling.set(1, 1, 1);
    });
    */

    engine.runRenderLoop(() => scene.render());

    const videoElement = document.getElementById("video");

    const faceMesh = new FaceMesh({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });

    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.5,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults(results => {
      if (results.multiFaceLandmarks && results.multiFaceLandmarks.length > 0) {
        const landmarks = results.multiFaceLandmarks[0];
        
        const forehead = landmarks[10];
        const chin = landmarks[152];

        const x = (forehead.x - 0.5) * 10;
        const y = -(forehead.y - 0.5) * 10;
        const z = (forehead.z) * 5;

        if (hat) {
          hat.position.set(x, y + 2, z);

          const dx = forehead.x - chin.x;
          const dy = forehead.y - chin.y;
          const dz = forehead.z - chin.z;

          hat.rotation.x = dy * 3;
          hat.rotation.y = -dx * 3;
          hat.rotation.z = dz * 3;
        }
      }
    });

    // Start camera and send video frames to MediaPipe
    const cameraUtils = new Camera(videoElement, {
      onFrame: async () => {
        await faceMesh.send({image: videoElement});
      },
      width: 640,
      height: 480
    });
    cameraUtils.start();
  </script>
</body>
</html>
